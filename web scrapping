import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

base_url = "http://books.toscrape.com/catalogue/page-{}.html"

book_titles = []
book_prices = []
book_ratings = []
page_number = 1

while True:
    page_url = base_url.format(page_number)
    response = requests.get(page_url)
    
    if response.status_code != 200:
        print(f"Reached the end of pages or encountered an error: {response.status_code}")
        break
    
    soup = BeautifulSoup(response.text, "html.parser")
    
    for book in soup.find_all("article", class_="product_pod"):
        # Extract the book title
        title = book.h3.a["title"]
        book_titles.append(title)

        price = book.find("p", class_="price_color").get_text(strip=True)
        book_prices.append(price)

        rating = book.p.get("class", [])
        rating_class = rating[1] if len(rating) > 1 else "No rating"
        book_ratings.append(rating_class)

    print(f"Scraped page {page_number} successfully.")
    page_number += 1
    
    time.sleep(1)

data = pd.DataFrame({
    "Title": book_titles,
    "Price": book_prices,
    "Rating": book_ratings
})

data.to_csv("books.csv", index=False)
print("Data has been saved to books.csv")
